\subsection{Анализ существующих решений} \label{indexes}

Для создания структуры данных, которая может помочь решить задачу пропуска нерелевантных файлов для интервальных запросов, необходимо ознакомиться с существующими решениями в платформах для доступа к данным. Существует множество специфичных индексов, решающих разные задачи, однако одно из определенных нами требований --- возможность индексировать разные типы данных, таким образом для рассмотрения не подходят индексы работающие, например, только со строковыми типами. Более того, для решения задачи необходима поддержка интервальных предикатов. В существующих платформах для доступа к данным таких решений несколько, это: упрощенные сводки, точные индексы и фильтры Блума \cite{Extensible_data_skipping}.

\subsubsection{Упрощенные сводки} 

В параграфе \ref{definition} уже была рассмотрена структура данных {<<Упрощенные сводки>>}. Более того, было доказано (Теорема \ref{theorema} ), что такая структура данных является оптимальной для интервальных неограниченных запросов. Однако для интервальный ограниченных запросов ...

Для повышения эффективности обработки запросов облачные сервисы анализа данных обычно применяют легковесные агрегации [14] для каждого блока, чтобы избежать необязательного доступа к нерелевантным блокам данных в процессе обработки запроса. Одной из наиболее распространённых форм легковесных агрегаций является ZoneMap, которая включает в себя хранение минимальных и максимальных значений, а также количества нулевых записей для каждого столбца в блоке данных. Например, если в блоке данных ZoneMap указано, что диапазон дат охватывает период с апреля по май, и запрос ищет записи за февраль, то данный блок может быть исключён из процесса чтения данных из хранилища, так как он не содержит необходимых данных.

ZoneMap — это тривиальная структура, которая не требует детального описания. Эти структуры просты в использовании и требуют минимальных затрат на хранение. Более того, размер такой структуры не зависит от объёма данных, который она описывает, что позволяет оценить затраты по памяти на хранение таких структур как O(1). Однако их эффективность зависит от конкретного расположения данных внутри блока.

В действительности ZoneMap оказывается эффективным для упорядоченных атрибутов, таких как целочисленные первичные ключи, однако такие атрибуты не являются ключевыми в сценариях использования больших данных для интервальных запросов. Эти атрибуты необходимы для корректной операции вставки данных в соответствующий файл данных для поддержки исторических запросов, но этот аспект выходит за рамки данной работы. Стоит отметить, что для управления такими операциями обычно подходят точные структуры данных, так как ложноположительные ответы могут нивелировать преимущества небольшого размера структур. Это связано с тем, что операция вставки обновлённой версии существующей записи является точечной операцией. Для неупорядоченных атрибутов, которые являются более типичным сценарием использования, такие структуры неэффективны, поскольку диапазоны значений в блоках могут охватывать большую часть предикатов запроса, что приводит к необходимости полного сканирования множества нерелевантных блоков.

Несмотря на ограничения легковесных агрегаций, этот подход избавлен от недостатков точных индексов и фильтров Блума. Важно заключить, что в контексте больших данных такие структуры могут оказаться неэффективными, однако они применимы для таблиц большого размера в традиционных СУБД, где их использование напоминает блочные индексы [15].

В то же время данный подход может оказаться полезным, если его адаптировать не к физическим файлам данных, а к общему множеству ключей. Эффективно разделить все упорядоченное множество ключей на непересекающиеся блоки, где каждый блок содержит информацию о минимальном и максимальном значениях, а необходимые данные для пропуска нерелевантных блоков определяются расположением файлов данных, ассоциированных с данным множеством ключей. Такой подход, хоть и сохраняет легковесность, имеет размер индекса, который растет линейно относительно количества записей в индексируемом наборе данных.


\subsubsection{Точные индексы} 

Одним из наиболее распространённых методов в системах управления базами данных (СУБД) является создание индексов, отображающих значение атрибута каждой отдельной записи на её расположение в таблице. Такой подход приводит к формированию семейства индексов на уровне записей, где каждая запись в индексе соответствует записи в таблице, требуя выделения O(N) памяти [3]. Обычно для этих целей используются B-деревья.

Основная проблема данного подхода заключается в том, что объём индекса становится соразмерным с объёмом данных. Согласно документации Hudi, размер одной записи в точном индексе составляет приблизительно 50 байт [2]. Для оценки размера индекса относительно размера данных предположим, что размер записи составляет 100 КБ. В таком случае для таблицы объёмом 100 ТБ размер индекса достигнет 50 ГБ, что делает его непригодным для полной загрузки в оперативную память. При этом размер индекса линейно зависит от объёма данных. Данная оценка учитывает, что данные хранятся в сжатом виде, а метаданные — без избыточности.

Таким образом, использование подобных индексов ограничено данными небольшого размера по сравнению с типичными сценариями применения на платформах для работы с большими данными. Более того, принятый в расчётах размер записи в 100 КБ не является минимально возможным. В зависимости от кодировки и метода сжатия, каждая запись в такой таблице может содержать примерно 104 символов, что характерно для аналитических систем. Схема такой таблицы должна включать порядка 102 атрибутов или содержать большой объём текста при меньшем количестве атрибутов. Однако, если таблица содержит десятки атрибутов и средний размер значения атрибута в байтах не превышает сотни, то размер индекса становится сопоставим с размером всего набора данных. При фиксированном размере индексной записи в 50 байт и размере записи в 100 байт, использование такого индекса становится нецелесообразным уже при размере таблицы в сотни гигабайт, что является типичным для классических СУБД, но не для озер данных.

Из анализа индексов, в которых количество записей соответствует количеству записей в таблице, следует важный вывод: хранение точного 	расположения каждой записи неосуществимо в реальных условиях использования платформ озёр данных. Для преодоления этой проблемы могут быть применены вероятностные структуры данных, рассмотрение которых представлено далее.

\subsubsection{Фильтр Блума} 

Одним из наиболее распространенных вероятностных подходов к отсеиванию файлов, не содержащих данных, удовлетворяющих заданному предикату, является применение структуры данных, известной как «фильтр Блума» [4].

Фильтр Блума состоит из битового массива длиной m бит и набора k различных хеш-функций h, которые генерируют значения от 0 до m−1, соответствующие позициям битов в массиве. В начальном состоянии, когда структура данных не содержит элементов, все биты массива установлены в ноль.

Фильтр Блума реализует вероятностное множество с двумя основными операциями: добавлением элемента в множество и проверкой принадлежности элемента множеству. Для добавления элемента e необходимо установить в единицу биты на позициях h1(e), …, hk(e). Для проверки принадлежности элемента достаточно вычислить значения хеш-функций для этого элемента и убедиться, что все соответствующие биты установлены в единицу, что дает ответ "возможно". Если хотя бы один бит не установлен в единицу, это означает, что элемент не принадлежит множеству — ответ "нет" [5].

Существует множество фильтров, основанных на концепции фильтра Блума, каждый из которых имеет свои преимущества и недостатки, например, кукушечный фильтр [6]. Тем не менее, общая идея, а также основные преимущества и недостатки остаются неизменными.

Основным преимуществом фильтра Блума является его простота реализации, что и обусловило его широкую популярность. Фильтры Блума используются не только в контексте больших данных, но и в задачах дедупликации данных, в сетевых технологиях, файловых системах и других областях. Несмотря на простоту, фильтр Блума остаётся очень компактной структурой данных. Его размер значительно меньше индексируемого набора данных. Однако, для поддержания приемлемого уровня ошибок необходимо увеличивать размер битового массива при увеличении объема данных. В целом, фильтр Блума представляет собой достаточно компактную структуру данных, которая демонстрирует заметную экономию пространства.

Основным недостатком фильтра Блума в контексте отсеивания избыточных файлов данных является необходимость прочитать либо все фильтры, если каждому файлу данных соответствует отдельный фильтр, либо прочитать весь фильтр, если он ассоциирован со всеми файлами данных, содержащими индексируемый атрибут. Кроме того, стандартная реализация фильтра Блума не предполагает возможность удаления элемента из индекса, поскольку это может привести к ложноотрицательным результатам, что недопустимо в данной задаче.

Однако наиболее значимым недостатком фильтра Блума является его неспособность обрабатывать интервальные запросы, которые часто используются в аналитических системах. Фильтр Блума эффективно отвечает на запросы о принадлежности одного ключа множеству, но при необходимости проверить принадлежность каждого ключа из заданного интервала, временная сложность операции составляет O(N×M), где N — количество проверяемых фильтров, а M — количество ключей в интервале. Учитывая, что размер множества ключей может быть неограничен для неограниченных интервальных запросов, это делает фильтр Блума непригодным для эффективной обработки таких запросов.

Таким образом, несмотря на то что структуры данных, основанные на фильтре Блума, широко используются в задачах, связанных с большими данными, они не подходят для решения задач отсеивания избыточных файлов данных из-за необходимости чтения всей структуры данных и невозможности обработки интервальных запросов, которые являются наиболее частыми в аналитических системах.


\fbox{это перенести во 2 главу??}

Существуют также эвристические подходы, которые используют закономерности в данных. Например, подход Sieve основан на наблюдении, что близкие по значению ключи часто находятся в одном и том же наборе данных, или распределены среди различных файлов данных [1]. Sieve использует кумулятивную распределительную функцию для определения размера следующего индексного блока: если значения функции для ключей k и k−1 указывают на одинаковые множества расположений, значение функции равно 0; в противном случае — 1. Sieve группирует множество ключей, относящихся к одному и тому же набору блоков, в отдельный сегмент. Эта идея схожа с принципом легковесных агрегаций, однако предлагает большую гибкость в построении индексов.

На данном этапе возможно синтезировать структуру данных, объединяющую преимущества различных подходов, с учетом существующих ограничений предметной области. Это позволит описать структуру, эффективно отсеивающую ненужные файлы данных и ускоряющую выполнение запросов.

Целесообразно использовать подход Sieve для выявления трендов в распределении ключей между файлами данных. К каждому полученному сегменту применяется классический метод блочных индексов. Каждый сегмент делится на блоки равной длины, содержащие информацию о расположении каждого ключа в интервале [l; r].

Для быстрого нахождения необходимого множества блоков отмечается, что при выполнении интервальных запросов в такой структуре требуется последовательное считывание расположенных подряд блоков. Для решения этой задачи в классических СУБД обычно используются B-деревья и их модификации. Оптимальная скорость сканирования в B-деревьях достигается за счет использования структуры в виде плоского дерева, где каждый узел представляет собой сегмент. Учитывая, что размер каждого блока внутри сегмента фиксирован, точечный запрос в такой структуре можно выполнить за время O(logN), а затем найти нужный блок можно за константное время. Для интервальных запросов требуется последовательное чтение следующих блоков. Такой подход к индексации данных будем называть "Сито", а реализуемую структуру данных — "Сито-индексом".

\section*{Выводы}
\addcontentsline{toc}{section}{Выводы}

Каждый подход к созданию индексных структур обладает определенными преимуществами и недостатками. Однако в условиях обработки больших объемов данных возможно эффективно сочетать наилучшие характеристики каждой системы для формирования оптимальной легковесной структуры. Такая структура должна быть не только эффективной с точки зрения использования памяти, но и обеспечивать приемлемый уровень точности ответов на реальных данных с минимальным количеством ложноположительных результатов.

Синтезированная структура, названная Сито-индексом, объединяет подходы, описанные в параграфах 1.3.1 и 1.3.3, и представляет собой вероятностную структуру данных. Она использует кумулятивную распределительную функцию для определения размера индексных блоков, применяет метод блочных индексов для группировки ключей и образует структуру B-дерева, что облегчает поиск и ускоряет выполнение запросов.

Сито-индекс обеспечивает гибкость при работе с большими объемами данных, путем подбора оптимального размера блока для разных участков данных и может быть оптимизирован для различных сценариев использования в зависимости от специфических требований.
