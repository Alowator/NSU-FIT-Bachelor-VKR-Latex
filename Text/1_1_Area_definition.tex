\section{Предметная область и текущие решения}
\subsection{Предметная область}\label{subsec:definition}

В научной литературе существует множество определений термина \textbf{большие данные}~\cite{Bigdata_a_review, Bigdata_an_introduction, Challenges_of_big_data_analysis}. Однако в рамках данной работы целесообразно выделить общие характеристики из всех предложенных определений. 

Распространенной ошибкой при определении понятия большие данные является попытка придать данным численную оценку объема, потому что объем данных, классифицируемых как большие, не только постоянно увеличивается, но и зависит от возрастающих вычислительных мощностей систем, на которых эти данные обрабатываются и хранятся. 

Несмотря на необходимость дать численные оценки для данных в некоторых частях данной работы, это не противоречит основному свойству больших данных --- их нельзя эффективно обработать или хранить на одном вычислительном узле. Следовательно, обработка таких объемов данных требует использования множества вычислительных узлов, которые работают над одной задачей и видны пользователям как одна цельная система, такие системы называются \textbf{распределенными}~\cite{Time_clocks_and_the_ordering_of_events_in_a_distributed_system}.

Распределенные системы для обработки больших данных состоят из множества сервисов, однако их можно разделить на три уровня~\cite{Spatial_big_data_architecture}:
\begin{enumerate}
    \item \textbf{Система обработки данных} --- распределенная вычислительная система (кластер), которая отвечает на запросы пользователей.
    \item \textbf{Система доступа к данным} --- управляет организацией данных для быстрого доступа к ним.
    \item \textbf{Хранилище данных} --- внешний распределенный сервис, доступ к которому осуществляется по сети.
\end{enumerate}
Системы с такой организацией будем называть \textbf{платформами для обработки больших данных}.

Именно системы для доступа к данным организуют структуру файлов в хранилище данных для более быстрого доступа к ним. Например, одной из систем для хранения и доступа к данным является Apache Hudi~\cite{Hudi} --- транзакционная система доступа к данным, которая поддерживает исторические запросы, а также отвечает за консистентность данных при записи и чтении. В первом приближении такую систему можно охарактеризовать как формат хранения данных. В качестве хранилища она использует~\cite{Hudi} файловую систему Hadoop Distributed File System (HDFS), являющуюся частью проекта Apache Hadoop.

Для систем существует два способа увеличения общей производительности, а также увеличения предельного объема данных, который возможно сохранить в системе~\cite{Advanced_computer_architecture_and_parallel_processing}:
\begin{enumerate}
    \item \textbf{Горизонтальное масштабирование} ---  увеличение количества отдельных вычислительных узлов в системе, выполняющих одну и ту же функцию.
    \item \textbf{Вертикальное масштабирование} --- увеличение производительности каждого вычислительного узла системы, путем использования более производительных компонентов и более объемных устройств хранения данных.
\end{enumerate}

В распределенных системах используют именно горизонтальное масштабирование~\cite{Advanced_computer_architecture_and_parallel_processing} ввиду природы распределенных систем, а также дешевизны такого масштабирования, так как распределенная система по определению содержит множество узлов, и добавление новых является для таких систем естественным процессом.

Выбор конкретной реализации хранилища данных не важен в контексте данной работы, так как все они обладают общими свойствами --- это внешние  сервисы, взаимодействие с которыми происходит по сети. Такие системы используются в платформах для обработки больших данных ввиду того, они системы хорошо масштабируются горизонтально. Это необходимо для надежного хранения данных и возможности дешевого добавления памяти в файловую систему~\cite{Distributed_File_Systems_Architectures}.

Такая архитектура приводит к тому, что самое узкое место всей платформы при обработке данных --- доступ к данным, так как скорость чтения данных по сети на порядки ниже скорости чтения данных с локального запоминающего устройства или оперативной памяти~\cite{HOI_BigData}. Существует разные способы организации данных для быстрого их чтения~\cite{Column_oriented_database_systems}, позволяющие сократить время обработки запроса. Тем не менее, ускорение выполнения запросов возможно и другими путями, один из них --- отсеивание файлов с данными, которые не удовлетворяют предикату запроса. Действительно, если для выполнения запроса нам нужны только записи за период, например, с января по март каждого года, то чтение файлов, которые содержат данные только за месяцы, отличные от заданных, можно пропустить. Такой способ ускорения запросов эффективен, так как мы уже выяснили, что чтение данных с внешнего файлового хранилища по сети является узким местом.

Для дальнейшего описания предметной области необходимо дать несколько определений:
\begin{definition}\label{def:conditional_query}
    \textbf{Запрос с условием} --- запрос к системе доступа к данным с условием (условиями) в виде предикатов, которые позволяют определить, какие данные будут включены в результирующий набор.
\end{definition}
\begin{definition}\label{def:useless_file}
    \textbf{Нерелевантный файл} --- файл с данными, который не содержит данных, удовлетворяющих предикату запроса, то есть файл, чтение которого можно пропустить для ускорения выполнения запросов с предикатами.
\end{definition}

Без ограничения общности в дальнейшем будем рассматривать запросы с условиями, в которых содержатся предикаты только по одному атрибуту. Тогда запросы с условиями можно разделить на три вида:
\begin{enumerate}
    \item \textbf{Точечный запрос} ---  запрос записей с предикатом равенства атрибута одному определенному значению.
    \item \textbf{Интервальный ограниченный запрос} --- запрос записей со значениями атрибута из интервала, ограниченного с обеих сторон.
    \item \textbf{Интервальный неограниченный запрос} --- запрос записей со значениями атрибута из интервала, ограниченного только с одной стороны.
\end{enumerate}
Таким образом, любые другие составные запросы являются комбинацией перечисленных выше запросов.

Существующие методы отсеивания файлов с данными используют \textbf{упрощенные сводки} --- минимальные и максимальные значения каждого атрибута для каждого файла данных, чтобы фильтровать те файлы, в которых не содержится записей, который удовлетворяют предикату запроса~\cite{Extensible_data_skipping, Small_Materialized_Aggregates}. Данная структура является оптимальной по памяти и времени для интервальных неограниченных запросов. Вполне вероятно, что такое утверждение уже описано в литературе, однако автор данной работы не нашел формального доказательства этого факта, поэтому далее приводится авторское формальное доказательство:
\begin{theorem}[Об оптимальности упрощенных сводок]\label{theorema}
    Для неограниченных интервальных запросов фильтрация файлов на основе упрощенных сводок требует $O(1)$ дополнительной памяти и $O(1)$ времени на фильтрацию одного файла с данными. Таким образом, для неограниченных интервальных запросов такая фильтрация является асимптотически оптимальной.
\end{theorem}
\proof

Дан файл, содержащий набор данных $\{v_1, v_2, \ldots, v_n\}$ из некоторого интервала $[a, b]$. Также задан предикат запроса $P(x)$, который может быть либо лучем вправо: $P(x) = (x \geq c)$, либо лучем влево: $P(x) = (x \leq c)$, где $c$ — некоторая константа.

Для хранения минимального и максимального значений файла требуется хранить всего два элемента в памяти, что составляет $O(1)$ памяти.

Проверка пустоты пересечения диапазона $[v_{\min}, v_{\max}]$ с диапазоном, заданным предикатом $P(x)$ может быть выполнена за время $O(1)$:
\begin{itemize}
    \item Если $P(x) = (x \geq c)$, то для файла предикат ложен только при $v_{\max} < c$, и в этом случае файл можно пропустить.
    \item Если $P(x) = (x \leq c)$, то для файла предикат ложен только при $v_{\max} > c$, и в этом случае файл можно пропустить.
\end{itemize}
\thmp

Однако такая структура не является асимптотически оптимальной для точечных и интервальных ограниченных запросов. Например, каждый файл с данными может содержать удаленные друг от друга значения --- отметки времени только за январь и только за декабрь определенного года, но при этом не содержать значений внутри этого диапазона. Тогда для точечных запросов, например, за конкретный день июля, или для запросов, нацеленных на извлечение данных за ограниченный с двух сторон период, например, с июня по август того же года, такой подход приведет к необходимости чтения файлов, которые не содержат нужной информации.

Соответственно, задача фильтрации нерелевантных файлов остается актуальной для точечных и интервальных ограниченных запросов. В дальнейшем в данной работе интервальные ограниченные запросы будем называть интервальными запросами.

Таким образом, предметной областью данной работы является индексация файлов и фильтрация нерелевантных файлов с данными для быстрого выполнения интервальных запросов чтения в распределенных базах данных.
