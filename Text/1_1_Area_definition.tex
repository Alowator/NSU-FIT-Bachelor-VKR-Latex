\section{Предметная область и текущие решения}
\subsection{Предметная область} \label{definition}

В научной литературе существует множество определений термина \textbf{большие данные} \cite{Bigdata_a_review, Bigdata_an_introduction, Challenges_of_big_data_analysis}. Однако в рамках данной работы целесообразно выделить общие характеристики из всех предложенных определений. 

Распространённой ошибкой при определении понятия большие данные является попытка придать данным численную оценку объёма, потому что объём данных, классифицируемых как большие, не только постоянно увеличивается, но и зависит от возрастающих вычислительных мощностей систем, на которых эти данные обрабатываются и хранятся. 

Несмотря на необходимость дать численные оценки для данных в некоторых частях данной работы, это не противоречит основному свойству больших данных --- их нельзя эффективно обработать или хранить на одном вычислительном узле. Следовательно, обработка таких объёмов данных требует использования множества вычислительных узлов, которые работают над одной задачей и видны пользователям как одна цельная система, такие системы называются \textbf{распределенными} \cite{Time_clocks_and_the_ordering_of_events_in_a_distributed_system}.

Распределенные системы для обработки больших данных состоят из множества сервисов, однако их можно разделить на три уровня: \cite{Spatial_big_data_architecture}
\begin{enumerate}
    \item \textbf{Системы обработки данных} --- распределенная вычислительная система (кластер), которая отвечает на запросы пользователей.
    \item \textbf{Система доступа к данным} --- управляет организацией данных для более быстрого доступа к ним.
    \item \textbf{Хранилище данных} --- внешний распределенный сервис, доступ к которому осуществляется по сети.
\end{enumerate}
Системы с такой организацией будем называть \textbf{платформами для обработки больших данных}.

Именно системы для доступа к данным организуют структуру файлов в хранилище данных для более быстрого доступа к ним. Например, одной из систем для хранения и доступа к данным является Apache Hudi --- транзакционная система для доступа к данным, которая поддерживает исторические запросы, а также отвечает за консистентность данных при записи и чтении. В первом приближении такую систему можно охарактеризовать как формат хранения данных. В качестве хранилища она использует файловую систему Hadoop Distributed File System (HDFS), являющуюся частью проекта Apache Hadoop. \fbox{откуда информация?}

Для систем существует два способа увеличения общей производительности, а также увеличения предельного объема данных, который возможно сохранить в системе: \cite{Advanced_computer_architecture_and_parallel_processing}
\begin{enumerate}
    \item \textbf{Горизонтальное масштабирование} ---  увеличение количества отдельных вычислительных узлов в системе, выполняющих одну и ту же функцию.
    \item \textbf{Вертикальное масштабирование} --- увеличение производительности каждого вычислительного узла системы, путем использования более производительных компонентов и более объемных устройств хранения данных.
\end{enumerate}

В распределенных системах используют именно горизонтальное масштабирование ввиду природы распределенных систем, а также дешевизны такого масштабирования, так как распределенная система по определению содержит множество узлов, и добавление новых является для таких систем естественным процессом \cite{Advanced_computer_architecture_and_parallel_processing}.

Выбор конкретной реализации хранилища данных не важен в контексте данной работы, так как все они обладают общими свойствами --- это внешние  сервисы, взаимодействие с которыми происходит по сети. Такие системы используются в платформах для обработки больших данных ввиду того, что такие системы хорошо масштабируются горизонтально. Это необходимо для надежного хранения данных и возможности дешевого добавления памяти в файловую систему \cite{Distributed_File_Systems_Architectures}.

Такая архитектура приводит к тому, что самое узкое место всей платформы при обработке данных --- доступ к данным, так как скорость чтения данных по сети на порядки ниже скорости чтения данных с локального запоминающего устройства или оперативной памяти \cite{HOI_BigData}. Существует множество способов организации данных для более быстрого их чтения\fbox{например, колоночный формат хранения данных?}, что позволяет сократить время обработки запроса. Тем не менее, ускорение выполнения запросов возможно и другими путями, один из них --- отсеивание файлов с данными, которые не удовлетворяют предикату запроса. Действительно, если для выполнения запроса нам нужны только записи за период, например, с января по март каждого года, то чтение файлов, которые содержат данные только за месяцы, отличные от заданных, можно пропустить. Такой способ ускорения запросов действительно эффективен, так как мы уже выяснили, что чтение данных с внешнего файлового хранилища по сети является узким местом.

Для дальнейшего определения предметной области необходимо дать несколько определений:
\begin{definition}
    \textbf{Запрос с условием} --- запрос к системе доступа к данным с фильтром (фильтрами) в виде предикатов, которые позволяют определить, какие данные будут включены в результирующий набор.
\end{definition}
\begin{definition}
    \textbf{Нерелевантный файл} --- файл с данными, который не содержит данных, удовлетворяющих предикату запроса, то есть файл, чтение которого можно пропустить для ускорения выполнения условного запроса.
\end{definition}

Не умаляя общности в дальнейшем будем рассматривать запросы с условиями, в которых содержатся предикаты только по одному атрибуту. Тогда запросы с условиями можно разделить на три вида:
\begin{enumerate}
    \item \textbf{Точечный запрос} ---  запрос записей с предикатом равенства одному определенному значению.
    \item \textbf{Интервальный ограниченный запрос} --- запрос записей на интервале, ограниченном с обеих сторон.
    \item \textbf{Интервальный неограниченный запрос} --- запрос записей на интервале, ограниченном только с одной стороны.
\end{enumerate}
Таким образом, любые другие составные запросы являются комбинацией перечисленных выше запросов.

Существующие методы отсеивания файлов с данными используют \textbf{упрощённые сводки} --- минимальные и максимальные значения каждого атрибута для каждого файла данных, чтобы фильтровать те файлы, в которых не содержится записей, который удовлетворяют предикату запроса \cite{Extensible_data_skipping, Small_Materialized_Aggregates}. Данная структура является оптимальной по памяти и времени для интервальных неограниченных запросов. Вполне вероятно, что такое утверждение уже описано в литературе, однако автор данной работы не нашел формального доказательства этого факта, поэтому далее приводится авторское формальное доказательство:
\begin{theorem}[Об оптимальности упрощенных свободок] \label{theorema}
    Фильтр на основе упрощенных сводок является оптимальным по используемой памяти и времени на фильтрацию одного файла с данными для интервальных неограниченных запросов.
\end{theorem}
\proof

Дан файл, содержащий набор данных $\{v_1, v_2, \ldots, v_n\}$ из некоторого интервала $[a, b]$. Также задан предикат $P(x)$, который может быть либо лучем вправо: $P(x) = (x \geq c)$, либо лучем влево: $P(x) = (x \leq c)$, где $c$ — некоторая константа.

Для хранения минимального и максимального значений файла требуется всего два элемента в памяти, что составляет $O(1)$ памяти.

Проверка предиката $P(x)$ на диапазон $[v_{\min}, v_{\max}]$ может быть выполнена за время $O(1)$:
\begin{itemize}
    \item Если $P(x) = (x \geq c)$, то предикат истинно для всех значений в файле, если $v_{\max} \geq c$, и ложно, если $v_{\min} < c$.
    \item Если $P(x) = (x \leq c)$, то предикат истинно для всех значений в файле, если $v_{\min} \leq c$, и ложно, если $v_{\max} > c$.
\end{itemize}
\thmp

Однако такая структура не является оптимальной для точечных и интервальных ограниченных запросов. Например, каждый файл с данными может содержать удаленные друг от друга значения --- отметки времени только за январь и только за декабрь определенного года, но при этом не содержать значений внутри этого диапазона. Тогда для точечных запросов, например, за конкретный день июля, или для запросов, нацеленных на извлечение данных за ограниченный с двух сторон период, например, с июня по август того же года, такой подход приведет к необходимости чтения файлов, которые не содержат нужной информации.

Соответственно задача фильтрации нерелевантных файлов остается актуальной для точечных и интервальных ограниченных запросов. В дальнейшем в данной работе интервальные ограниченные запросы будем называть интервальными запросами.

Таким образом, предметной областью данной работы является индексация и фильтрация нерелевантных файлов с данными для их более быстрого чтения в распределенных базах данных при выполнении интервальных запросов.
