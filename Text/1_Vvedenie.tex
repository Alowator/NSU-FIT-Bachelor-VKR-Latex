\section*{Введение}
\addcontentsline{toc}{section}{Введение}

Современные платформы для анализа больших данных интегрированы с внешними сервисами хранения данных, что превращает ввод-вывод из удалённого распределённого хранилища в одно из основных узких мест при обработке запросов. Стандартными практиками на таких платформах являются организация данных в колоночные форматы и их сжатие, что позволяет сократить расходы на хранение и обработку данных. Тем не менее, эффективный пропуск нерелевантных блоков данных остаётся нерешённой проблемой.

Существующие методы пропуска нерелевантных блоков данных используют упрощённые сводки (например, минимальные и максимальные значения) для каждого блока данных, чтобы фильтровать нерелевантные данные, или же они точно нацелены на ускорение операций вставки данных. Однако эти методы часто неэффективны или вовсе не работают с реальными запросами данных, что приводит к неэффективному использованию ресурсов хранилища.

Целью данной работы является разработка оптимальных методов индексации данных для ускорения обработки запросов с условиями в контексте платформ больших данных на основе анализа существующих подходов и их применимости на практике.

Задача исследования состоит в разработке структуры данных, которая позволит ускорить обработку интервальных запросов в платформе Apache Hudi, а также в внедрении этой структуры данных в платформу с последующим проведением экспериментов на реальных наборах данных. \cite{tex, latex}
