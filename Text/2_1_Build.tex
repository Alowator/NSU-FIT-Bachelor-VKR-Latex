\subsection{Алгоритм построения}

Одно из ограничений в платформах для обработки больших данных --- ограниченный размер оперативной памяти вычислительных узлов (\ref{requirements}). Для того чтобы построить функцию $R$, необходимо отсортировать весь набор ключей и агрегировать все расположения каждого отдельного ключа для того чтобы отслеживать значение функции $R$. Так как размер всего множества ключей $K$ может не уместиться в оперативную память одного вычислительного узла, данную операцию необходимо производить с использованием системы для обработки данных \fbox{ссылка}, то есть производить данные вычисления, используя вычислительные ресурсы всего кластера, так как система для обработки данных имеют возможность работы с данными, которые не умещаются в оперативную память конкретного узла, при этом может задействоваться локальная файловая система узлов кластера, при недостатке оперативной памяти узлов \fbox{ссылка спарк?}. В данной работе системой для обработки данных является Apache Spark.

После формирования упорядоченного набора ключей вместе с множеством расположений каждого ключа, система для доступа к данным может приступит к формированию сегментов и сохранению их в хранилище данных, получая из вычислительного кластера каждый следующий ключ вместе с множеством его расположений один за одним и отслеживая значение ошибки для текущего сегмента. Формирование сегмента заканчивается при достижении им определенного размера (так как объем оперативной памяти вычислительного узла ограничен) или при достижении порога ошибки \fbox{что это}. После формирования очередного сегмента, необходимо вычислить размер блоков (\ref{partition_size}) внутри него и сформировать эти блоки, после чего сегмент сериализуется в хранилище данных и может быть выгружен из оперативной памяти. Таким образом возможно преодолеть ограничение оперативной памяти вычислительного узла.

Далее приведен алгоритм построения Сито-индекса:

    