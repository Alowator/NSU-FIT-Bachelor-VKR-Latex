\subsection{Алгоритм построения}\label{build}

Алгоритм построения состоит из двух этапов:

\begin{enumerate}
    \item {Сортировка ключей}.
    \item {Построение сегментов индекса}.
\end{enumerate}

Первый этап является вычислительно самым трудоемким, так как одно из ограничений в платформах для обработки больших данных --- ограниченный размер оперативной памяти вычислительных узлов (\ref{requirements}). Для того чтобы построить функцию $R$, необходимо отсортировать весь набор ключей для того чтобы отслеживать значение функции $R$. Так как размер всего множества ключей $K$ может не уместиться в оперативную память одного вычислительного узла и даже всех вычислительных узлов вместе взятых. Однако данную операцию возможно реализовать с использованием системы для обработки данных \fbox{ссылка}, то есть производить данные вычисления, используя вычислительные ресурсы всего кластера, так как система для обработки данных имеют возможность работы выполнения таких запросов как сортировка и агрегация данных, которые не умещаются в оперативную память, при этом может задействоваться локальная файловая система узлов кластера, при недостатке оперативной памяти вычислительных узлов \fbox{ссылка спарк?}. В данной работе системой для обработки данных является Apache Spark. Точкой входа для создания индекса является метод $createIndex$ в классе $SparkHoodieBackedTableMetadataWriter$:

Далее приводится алгоритм для формирования отсортированного набора данных, вычисление которого производится с использованием возможностей кластера Spark в распределенной среде:

\begin{enumerate}
    \item Создание отношения: Используется адаптер Spark, предоставляемый Apache Hudi, для создания отношения. Для этого вызывается метод $createRelation$, которому передаются SQL-контекст, мета-клиент Hudi, схема данных для чтения и массив путей к файлам.
    \item Преобразование отношения в набор данных: Полученное отношение преобразуется в набор данных с использованием метода $baseRelationToDataFrame$.
    \item Из набора данных выбираются две колонки: целевая колонка для индексации и колонка с именами файлов.
    \item Набор данных сортируется по значению колонки для индексации по возрастанию.
    \item Группировка и агрегация данных: Выполняется группировка данных по колонке для индексации. Применяется агрегирующая функция к колонке с именем файла, которая позволяет собрать уникальные значения имен файлов в каждой группе.
\end{enumerate}

Полученный набор данных, содержащий отсортированные и агрегированные данные, возвращается как результат.

Второй этап заключается в формировании сегментов и сохранению их в хранилище данных, получая из вычислительного кластера каждый следующий ключ вместе с множеством его расположений один за одним и отслеживая значение ошибки для текущего сегмента. Данную операция производится на одном вычислительном узле, так как для формирования сегментов индекса необходимо пройти все множество ключей по возрастанию один раз. Формирование очередного сегмента заканчивается при достижении им определенного размера (так как объем оперативной памяти вычислительного узла ограничен) или при достижении порога ошибки \fbox{что это}. После формирования очередного сегмента, необходимо вычислить размер блоков (\ref{partition_size}) внутри него и сформировать эти блоки, после чего сегмент сериализуется в хранилище данных и может быть выгружен из оперативной памяти. Таким образом возможно преодолеть ограничение оперативной памяти вычислительного узла и невозможность выполнить сегментацию на в системе обработки данных. Далее приведен алгоритм формирования сегментов Сито-Индекса:

\begin{enumerate}
\item Инициализация переменных:
    \begin{enumerate}
    \item Создается пустой список $segments$ для хранения метаданных сегментов индекса.
    \item Инициализируется объект $segmentBuilder$ для построения блоков текущего сегмента.
    \item Устанавливается значение погрешности сегмента $e = 100$.
    \item Инициализируются переменные $R_{value} = 0$, $prevKey$ (пустой) и $prevIds$ (пустое множество).
    \item Задаются начальные значения $slHigh = +inf$ и $slLow = 0$.
    \end{enumerate}

\item Итерация по набору данных из отсортированных ключей, для очередного ключа $k$:
    \begin{enumerate}
    \item Если текущий $segmentBuilder$ пуст, то в него добавляется $k$ и множество расположений $k$.
    \item Если сегмент не пуст:
        \begin{enumerate}
        \item Увеличивается значение $R_{value} = R_{value} + 1$, если текущий ключ отличается от предыдущего или если расположения ключа изменились.
        \item Вычисляется текущий наклон $sl =  R_{value} / (k - segmentBuilder_{minkey})$.
        \item Если наклон $sl$ выходит за границы $slHigh$ или $slLow$ или если сегмент заполнен:
            \begin{enumerate}
            \item Текущий сегмент сериализуется в хранилище данных, а его метаданные и добавляется в список $segments$.
            \item Инициализируется новый объект $segmentBuilder$.
            \item Значения $slHigh$, $slLow$ и $R_{value}$ инициализируются заново.
            \end{enumerate}
        \item $slHigh = min(slHigh, (R_{value} + e) / (k - segmentBuilder_{minkey}))$
        \item $slLow = max(slLow, (R_{value} - e) / (k - segmentBuilder_{minkey}))$
        \item $segmentBuilder.add(k, расположения k)$
        \end{enumerate}
    \item $prevKey = k$
    \item $prevIds = расположения k$
    \end{enumerate}
\item Если $segmentBuilder$ не пуст, то он сериализуется на файловое хранилище и его метаданные добавляются в список $segments$.
\item Список $segments$ сериализуется в хранилище данных --- это есть метаданных Сито-индекса.
\end{enumerate}

Реализация данного алгоритма в систему для доступа к данным Apache Hudi приведена в приложении В.
