\section{Сито-индекс и его внедрение в систему доступа к данным}

Для решения задачи пропуска нерелевантных файлов для интервальных запросов необходимо внедрить структуру данных, которая будет одновременно иметь небольшой размер относительно размера индексируемого атрибута (\ref{subsec:requirements}), то есть иметь размер индекса на ключ (\ref{eq:size_per_key}) такой, при котором накладные расходы на хранение и доступ к индексу не приведут к тому, что выполнение запроса с использованием индекса будет медленнее выполнения запроса без использования этого же индекса.

Стоит обратить внимание, что в постановке задачи (\ref{subsec:definition}) данные в каждом файле имеют некоторую закономерность, например, еще раз рассмотрим случай, когда упрощенные сводки (\ref{column_stats}) дают ложноположительный ответ: файл может содержать в качестве значений отметки времени за только январь и только за декабрь определенного года.
Тогда для запросов, нацеленных на извлечение данных за определенные периоды, например, с июня по август того же года, упрощенные сводки дадут ложноположительный ответ для данного файла.

Существуют эвристические подходы для построения индексов, которые используют закономерности в данных.
Например, подход Sieve~\cite{Sieve}, который основан на наблюдении, что \textbf{близкие по значению ключи часто находятся в одном и том же наборе данных}, или распределены среди различных файлов.
Именно данное предположение отражают те случаи, когда упрощенные сводки дают ложноположительные ответы, так как упрощенные сводки никак не учитывают реальное расположение данных внутри каждого файла.

Напомним, что под расположением в данной работе имеется ввиду путь к файлу и его идентификатор (\ref{subsec:systems_for_data_access}).

Sieve предлагает следующую модель для определения закономерности в распределении данных:

Пусть $k$ --- ключ из множества ключей $K$, тогда введем функцию R:
\begin{equation}\label{R_CDF}
R(k) = 
\begin{cases} 
    R(k - 1), & \text{если множества расположений $k$ и $k - 1$ равны}, \\
    R(k - 1) + 1, & \text{в остальных случая }.
\end{cases}
\end{equation}

Значение функции $R$ --- есть общее количество раз, когда набор расположений изменялся для двух соседних ключей.
Далее для построения модели производится линеаризация отдельных сегментов данной функции.
Таким образом каждый сегмент отражает некоторую закономерность в распределении ключей между файлами.
Например, если линеаризованный участок (сегмент) параллелен оси абсцисс, это значит, что множество расположений ключей в данном сегменте не менялось, соответственно для того чтобы сохранить информацию о данном сегменте можно использовать меньше памяти, достаточно сохранить минимальное и максимальное значений ключей для данного сегмента и множество расположений, в которых ключи из этого промежутка расположены, и напротив, если тангенс угла линеаризованного участка равен единице, это значит, что расположения ключей различаются для каждых соседних ключей, то есть этот участком необходимо разделить на более мелкие блоки, каждый из которых должен содержать информацию о минимальном и максимальном значении ключей каждого блока и множество расположений этих ключей, для того чтобы снизить вероятность ложноположительных ответов для этого сегмента.

Введем следующие обозначения:
$e$ - допустимая ошибка сегмента (конфигурируется), $s$ --- сегмент, $s_{min}, s_{max}$ --- соответственно минимальное и максимальное значения ключа в сегменте, $s_{size} = s_{max} - s_{min}$, $s.E$ --- предел дополнительных ложноположительных ответов для сегмента, $b$ --- блок, $b_{min}, b_{max}$ --- соответственно минимальное и максимальное значение ключа в блоке.

Существует множество вариантов линеаризации сегментов функции R, однако модель Sieve \cite{Sieve} предлагает следующий алгоритм, где $e$ - конфигурируемая допустимая ошибка.

\textbf{Алгоритм для выделения сегментов:}
\begin{enumerate}
\item $slLow = 0, slHigh = \infty$.
\item Для очередного ключа $k$ и значения функции $R(k)$ вычислим \mbox{$sl = R(k) / (k - s_{min})$}.
    \begin{enumerate}
    \item Если \mbox{$slLow < sl < slHigh$}, обновить значения:
    
    \mbox{$slHigh = min(slHigh, (R(k) + e) / (k - s_{min}))$}, \mbox{$slLow = max(slLow, (R(k) - e) / (k - s_{min}))$} и перейти к шагу 2.
    \item Иначе сегмент $s$ построен, начать построение нового сегмента перейдя к шагу 1.
    \end{enumerate}
\end{enumerate}

Используя данный подход, множество ключей $K$ разбивается на \textbf{сегменты}, каждый из которых свидетельствует о некоторой закономерности в распределении ключей, которые находится внутри данного сегмента. Далее каждый \textbf{сегмент разбивается на блоки} одинаковой длины, размер блока $b_{size}$ внутри сегмента определяется как:
\begin{equation}\label{eq:partition_size}
    b_{size} = \frac{s_{size}}{R(s_{max}) - R(s_{min}) + 1}
\end{equation}

Таким образом, вероятность ложноположительного ответа $b_{fpr}$ для блока:
\begin{equation}\label{eq:partition_fpr}
    b_{fpr} = 1 - \frac{1}{R(b_{max}) - R(b_{min})}
\end{equation}

Любой ключ принадлежит ровно одному блоку, таким образом это есть вероятность ошибки для одного любого ключа.

Далее мы разработаем структуру данных \textbf{<<Сито-индекс>>} после чего реализуем её~\cite{Sieve_Github} в системе для доступа данных Apache Hudi, которая является модификацией структуры данных {<<Sieve>>}, адаптированную под индексацию больших наборов данных, модифицируем алгоритм построения индекса и реализуем алгоритм его обновления.

Структура данных {<<Сито-индекс>>}, как и {<<Sieve>>}, состоит из сегментов, каждый из которых представляет собой отдельный файл в хранилище данных. Каждый такой файл содержит в себе множество блоков. Также отдельно вводится понятие \textbf{метаданные} Сито-индекса, это отдельный файл, в котором содержится список сегментов.

Каждый блок содержит в себе множество расположений $b.L$, в которых располагаются ключи из интервала $[b_{min}, b_{max}]$. Добавим для каждого существующего расположения $loc$ счетчик $b.L(loc)$, которым будем вести подсчет количества ключей, которые содержатся в данном расположении $loc$. Такое решение необходимо для реализации операций обновления индекса.

Далее разработаем операции над данной структурой данных, принимая ввиду ограничения платформ для обработки больших данных (\ref{subsec:requirements}).

